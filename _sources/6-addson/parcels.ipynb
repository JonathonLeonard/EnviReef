{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooked-agenda",
   "metadata": {},
   "source": [
    "# Particles tracking \n",
    "\n",
    "The [OceanParcels](http://oceanparcels.org) project develops `Parcels` (*Probably A Really Computationally Efficient Lagrangian Simulator*), a set of Python classes and methods to create customisable particle tracking simulations using output from Ocean Circulation models such as the eReefs one. \n",
    "\n",
    ":::{note}\n",
    "Parcels can be used to track passive and active particulates such as: \n",
    "+ water, \n",
    "+ plankton, \n",
    "+ [plastic](http://topios.org) and \n",
    "+ fish.\n",
    ":::\n",
    "\n",
    "In this notebook, we will first cover how to run a set of *particles* from exported [eReefs data](http://thredds.ereefs.aims.gov.au/thredds/catalog.html). Then we will show how to use particles to sample a field such as *temperature* and how to write a kernel that tracks the *distance travelled by the particles*.\n",
    "\n",
    "\n",
    ":::{seealso}\n",
    "The [OceanParcels](http://oceanparcels.org) team has designed a series of Jupyter notebooks to help people to get started with `Parcels`. You can find the tutorials on this [link](http://oceanparcels.org/#tutorials)!\n",
    ":::\n",
    "\n",
    "## Load the required Python libraries\n",
    "\n",
    "First of all, load the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import cmocean\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "cartopy.config['data_dir'] = os.getenv('CARTOPY_DIR', cartopy.config.get('data_dir'))\n",
    "\n",
    "from parcels import FieldSet, Field, ParticleSet, Variable, JITParticle\n",
    "from parcels import AdvectionRK4, plotTrajectoriesFile, ErrorCode\n",
    "\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "plt.ion()  # To trigger the interactive inline mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-bloom",
   "metadata": {},
   "source": [
    "## Build multi-file dataset\n",
    "\n",
    "We will use the `open_mfdataset` function from `xArray` to open multiple netCDF files into a single xarray Dataset. \n",
    "\n",
    "We will query load the GBR4km dataset from the [AIMS server](http://thredds.ereefs.aims.gov.au/thredds/catalog.html), so let's first define the base URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the hydro dataset\n",
    "base_url = \"http://thredds.ereefs.aims.gov.au/thredds/dodsC/s3://aims-ereefs-public-prod/derived/ncaggregate/ereefs/gbr4_v2/daily-monthly/EREEFS_AIMS-CSIRO_gbr4_v2_hydro_daily-monthly-\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-technology",
   "metadata": {},
   "source": [
    "For the sake of the demonstration, we will only use 1 month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_st = 1   # Starting month \n",
    "month_ed = 1   # Ending month \n",
    "year = 2018    # Year\n",
    "\n",
    "# Based on the server the file naming convention \n",
    "hydrofiles = [f\"{base_url}{year}-{month:02}.nc\" for month in range(month_st, month_ed+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-vacuum",
   "metadata": {},
   "source": [
    "### Loading dataset into xArray\n",
    "\n",
    "Using `xArray`, we open these files into a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hydro = xr.open_mfdataset(hydrofiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-princeton",
   "metadata": {},
   "source": [
    "### Clip the Dataset\n",
    "\n",
    "To reduce the `Dataset` size we will clip the spatial extent based on longitudinal and latitudinal values. \n",
    "\n",
    "This is easely done using the `sel` function with the `slice` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lon = 146     # lower left longitude\n",
    "min_lat = -21     # lower left latitude\n",
    "max_lon = 150     # upper right longitude\n",
    "max_lat = -16     # upper right latitude\n",
    "\n",
    "# Defining the boundaries\n",
    "lon_bnds = [min_lon, max_lon]\n",
    "lat_bnds = [min_lat, max_lat]\n",
    "\n",
    "# Performing the reduction and only taking the surface dataset (k=-1)\n",
    "ds_hydro_clip = ds_hydro.sel(latitude=slice(*lat_bnds), longitude=slice(*lon_bnds), k=-1)\n",
    "ds_hydro_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-klein",
   "metadata": {},
   "source": [
    "We will now drop all unnecessary variables. \n",
    "\n",
    "Basically we will only need the current velocities (`u` and `v`) and the variable we want to track with the parcels (here `temp`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_data = ds_hydro_clip.drop(['zc','mean_wspeed','salt',\n",
    "                    'eta','wspeed_u','wspeed_v', \n",
    "                    'mean_cur'])\n",
    "\n",
    "surf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-scheduling",
   "metadata": {},
   "source": [
    "[OceanParcels](http://oceanparcels.org) will need to read the file locally and we save it using the `Xarray` funciton `to_netcdf`. Otherwise you could use the `from_xarray_dataset` function to directly read the dataset in `Parcels`.\n",
    "\n",
    ":::{note}\n",
    "Here the cell has been commented to make the notebook run faster, but you will need to uncomment it for running your how experiment...\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name ='ereefdata.nc'\n",
    "# try:\n",
    "#     os.remove(data_name)\n",
    "# except OSError:\n",
    "#     pass\n",
    "\n",
    "# surf_data.to_netcdf(path=data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-youth",
   "metadata": {},
   "source": [
    "## Reading velocities into Parcels\n",
    "\n",
    "As we used the `NetCDF` format, it is fairly easy to load the velocity fields into the `FieldSet.from_netcdf()` function available in `Parcels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'U': data_name,\n",
    "             'V': data_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-landing",
   "metadata": {},
   "source": [
    "Then, define a dictionary of the variables (`U` and `V`) and dimensions (`lon`, `lat` and `time`; note that in this case there is no depth because we only took the surface variables from the `eReefs` datastet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'U': 'u',\n",
    "             'V': 'v'}\n",
    "\n",
    "dimensions = {'lat': 'latitude',\n",
    "              'lon': 'longitude',\n",
    "              'time': 'time'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-landscape",
   "metadata": {},
   "source": [
    "Finally, we read in the fieldset using the `FieldSet.from_netcdf` function with the above-defined `filenames`, `variables` and `dimensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-penguin",
   "metadata": {},
   "source": [
    "Now define a `ParticleSet`, in this case with 5 particles starting on a line between (147E, 18.5S) and (148E, 17.5S) using the `ParticleSet.from_line` constructor method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = ParticleSet.from_line(fieldset=fieldset, pclass=JITParticle,\n",
    "                             size=5,               # releasing 5 particles\n",
    "                             start=(147, -18.5),   # releasing on a line: the start longitude and latitude\n",
    "                             finish=(148, -17.5))  # releasing on a line: the end longitude and latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-highlight",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Another approach if you want to list a series of initial positions consists in using the `from_list` [function](https://oceanparcels.org/gh-pages/html/#module-parcels.particlesets.particlesetsoa) which takes:\n",
    "+ lon – List of initial longitude values for particles\n",
    "+ lat – List of initial latitude values for particles\n",
    ":::\n",
    "\n",
    "Now we want to advect the particles. However, the eReefs data that we loaded in is only for a limited, regional domain and particles might be able to leave this domain. \n",
    "\n",
    "We therefore need to tell `Parcels` that particles that leave the domain need to be deleted. We do that using a `Recovery Kernel`, which will be invoked when a particle encounters an `ErrorOutOfBounds error`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-migration",
   "metadata": {},
   "source": [
    "Now we can advect the particles by executing the ParticleSet for 30 days using 4th order Runge-Kutta (`AdvectionRK4`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nc = 'CurrentParticles.nc'\n",
    "try:\n",
    "    os.remove(output_nc)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pset.ParticleFile(name=output_nc, \n",
    "                                outputdt=timedelta(hours=6))\n",
    "\n",
    "pset.execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=30),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=output_file,\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-prisoner",
   "metadata": {},
   "source": [
    "We now export the particles recorded every 6h in our output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-tribute",
   "metadata": {},
   "source": [
    "## Plotting outputs\n",
    "\n",
    "We open the particles file with `Xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = xr.open_dataset(output_nc)\n",
    "parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-furniture",
   "metadata": {},
   "source": [
    "We will now use the `Xarray` `plot` function as we have done in the past...\n",
    "\n",
    ":::{seealso}\n",
    "Check out this [link](https://xarray-contrib.github.io/xarray-tutorial/scipy-tutorial/04_plotting_and_visualization.html) to see how to use `Xarray`’s convenient matplotlib-backed plotting interface to visualize your datasets! \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "size = (9, 10)\n",
    "\n",
    "# Color from cmocean\n",
    "color = cmocean.cm.speed\n",
    "\n",
    "# Defining the figure\n",
    "fig = plt.figure(figsize=size, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Axes with Cartopy projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# and extent\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], ccrs.PlateCarree())\n",
    "\n",
    "# Plotting using Matplotlib \n",
    "# We plot the PH at the surface at the final recorded time interval\n",
    "cf = ds_hydro_clip.mean_cur.isel(time=10).plot( \n",
    "    transform=ccrs.PlateCarree(), cmap=color,\n",
    "    vmin = 0.1, vmax = 1.0, alpha=0.2, \n",
    "    add_colorbar=False\n",
    ")\n",
    "\n",
    "# Color bar\n",
    "cbar = fig.colorbar(cf, ax=ax, fraction=0.027, pad=0.045, \n",
    "                    orientation=\"horizontal\")\n",
    "cbar.set_label(ds_hydro_clip.mean_cur.long_name+' '+ds_hydro_clip.mean_cur.units, rotation=0, \n",
    "               labelpad=5, fontsize=10)\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "# Title\n",
    "plt.title('Parcels evolution',\n",
    "          fontsize=13\n",
    "         )\n",
    "\n",
    "# Plot lat/lon grid \n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=0.1, color='k', alpha=1, \n",
    "                  linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 8}\n",
    "gl.ylabel_style = {'size': 8} \n",
    "\n",
    "# Add map features with Cartopy \n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', \n",
    "                                            edgecolor='face', \n",
    "                                            facecolor='lightgray'))\n",
    "ax.coastlines(linewidth=1)\n",
    "\n",
    "for k in range(parcels.lon.shape[0]):\n",
    "    ax.scatter(parcels.lon.isel(traj=k), parcels.lat.isel(traj=k), s=40, edgecolors='w', \n",
    "               linewidth=0.2, transform=ccrs.PlateCarree()).set_zorder(11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-robertson",
   "metadata": {},
   "source": [
    "## Sampling a Field with Particles\n",
    "\n",
    "One typical use case of particle simulations is to sample a Field (such as temperature, salinity, surface hight) along a particle trajectory. In `Parcels`, this is very easy to do, with a `custom Kernel`.\n",
    "\n",
    "\n",
    "Let's define the `FieldSet` as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'U': data_name,\n",
    "             'V': data_name,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'U': 'u',\n",
    "             'V': 'v',\n",
    "            }\n",
    "\n",
    "dimensions = {'lat': 'latitude',\n",
    "              'lon': 'longitude',\n",
    "              'time': 'time'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-harmony",
   "metadata": {},
   "source": [
    "Finally, we read in the fieldset using the `FieldSet.from_netcdf` function with the above-defined `filenames`, `variables` and `dimensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-response",
   "metadata": {},
   "source": [
    "We now add the field `temperature` to the `FieldSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'lat': data_name,\n",
    "             'lon': data_name,\n",
    "             'data': data_name}\n",
    "\n",
    "variable = ('T', 'temp')\n",
    "\n",
    "dimensions = {'lat': 'latitude',\n",
    "              'lon': 'longitude',\n",
    "              'time': 'time'}\n",
    "\n",
    "field = Field.from_netcdf(filenames, variable, dimensions)\n",
    "fieldset.add_field(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-clark",
   "metadata": {},
   "source": [
    "Now define a new `Particle class` that has an extra Variable: the **temperature**. We initialise this by sampling the `fieldset2.T` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleParticle(JITParticle):          # Define a new particle class\n",
    "    t = Variable('t', initial=fieldset.T)  # Variable 't' initialised by sampling the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-citizen",
   "metadata": {},
   "source": [
    "Now define a `ParticleSet` using the `from_line` method also used above. Plot the `pset` and print their temperature values `t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = ParticleSet.from_line(fieldset=fieldset, pclass=SampleParticle, \n",
    "                             size=5,               # releasing 5 particles\n",
    "                             start=(147, -18.5),   # releasing on a line: the start longitude and latitude\n",
    "                             finish=(148, -17.5),  # releasing on a line: the end longitude and latitude\n",
    "                             time=0)\n",
    "print('t values before execution:', [p.t for p in pset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-eclipse",
   "metadata": {},
   "source": [
    "Now create a custom function that samples the `fieldset.T` field at the particle location. Cast this function to a Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampleT(particle, fieldset, time):  # Custom function that samples fieldset2.T at particle location\n",
    "    particle.t = fieldset.T[time, particle.depth, particle.lat, particle.lon]\n",
    "\n",
    "k_sample = pset.Kernel(SampleT)    # Casting the SampleT function to a kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-conservation",
   "metadata": {},
   "source": [
    "Finally, execute the pset with a combination of the `AdvectionRK4` and `SampleT` kernels, plot the pset and print their new temperature values `t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nc_temp = 'CurrentParticlesTemp.nc'\n",
    "try:\n",
    "    os.remove(output_nc_temp)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_temp = pset.ParticleFile(name=output_nc_temp, \n",
    "                                outputdt=timedelta(hours=6))\n",
    "\n",
    "pset.execute(AdvectionRK4 + k_sample,    # Add kernels using the + operator.\n",
    "             runtime=timedelta(days=30),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=output_file_temp,\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})\n",
    "\n",
    "output_file_temp.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-navigator",
   "metadata": {},
   "source": [
    "### Plotting the result\n",
    "\n",
    "We can extract the netcdf file values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_temp = xr.open_dataset(output_nc_temp)\n",
    "parcels_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-weapon",
   "metadata": {},
   "source": [
    "And plot the resulting parcels output on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "size = (9, 10)\n",
    "\n",
    "# Color from cmocean\n",
    "color = cmocean.cm.speed\n",
    "\n",
    "# Defining the figure\n",
    "fig = plt.figure(figsize=size, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Axes with Cartopy projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# and extent\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], ccrs.PlateCarree())\n",
    "\n",
    "# Plotting using Matplotlib \n",
    "# We plot the PH at the surface at the final recorded time interval\n",
    "cf = ds_hydro_clip.mean_cur.isel(time=10).plot( \n",
    "    transform=ccrs.PlateCarree(), cmap=color,\n",
    "    vmin = 0.1, vmax = 1.0, alpha=0.2, \n",
    "    add_colorbar=False\n",
    ")\n",
    "\n",
    "# Color bar\n",
    "cbar = fig.colorbar(cf, ax=ax, fraction=0.027, pad=0.045, \n",
    "                    orientation=\"horizontal\")\n",
    "cbar.set_label(ds_hydro_clip.mean_cur.long_name+' '+ds_hydro_clip.mean_cur.units, rotation=0, \n",
    "               labelpad=5, fontsize=10)\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "# Title\n",
    "plt.title('Parcels evolution coloured by surface temperature',\n",
    "          fontsize=13\n",
    "         )\n",
    "\n",
    "# Plot lat/lon grid \n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=0.1, color='k', alpha=1, \n",
    "                  linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 8}\n",
    "gl.ylabel_style = {'size': 8} \n",
    "\n",
    "# Add map features with Cartopy \n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', \n",
    "                                            edgecolor='face', \n",
    "                                            facecolor='lightgray'))\n",
    "ax.coastlines(linewidth=1)\n",
    "\n",
    "distmin = parcels_temp.t.min().item()\n",
    "distmax = parcels_temp.t.max().item()\n",
    "\n",
    "for k in range(parcels_temp.lon.shape[0]):\n",
    "    sc = plt.scatter(parcels_temp.lon.isel(traj=k), parcels_temp.lat.isel(traj=k), s=40, \n",
    "               c=parcels_temp.t.isel(traj=k), edgecolors='k', \n",
    "               cmap=cmocean.cm.balance, vmin=distmin, vmax=distmax, \n",
    "               linewidth=0.2, transform=ccrs.PlateCarree()).set_zorder(11)\n",
    "\n",
    "# Color bar\n",
    "cbar2 = plt.colorbar(sc, ax=ax, fraction=0.027, pad=0.045)\n",
    "cbar2.set_label('Surface temperature in degree C', rotation=90, \n",
    "               labelpad=5, fontsize=10)\n",
    "cbar2.ax.tick_params(labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-directory",
   "metadata": {},
   "source": [
    "## Calculating distance travelled\n",
    "\n",
    "As a second example of what custom kernels can do, we will now show how to create a kernel that logs the total distance that particles have travelled.\n",
    "\n",
    "First, we need to create a new `Particle class` that includes three extra variables. The distance variable will be written to output, but the auxiliary variables `prev_lon` and `prev_lat` won't be written to output (can be controlled using the `to_write` keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistParticle(JITParticle):  # Define a new particle class that contains three extra variables\n",
    "    \n",
    "    distance = Variable('distance', initial=0., dtype=np.float32)  # the distance travelled\n",
    "    prev_lon = Variable('prev_lon', dtype=np.float32, to_write=False,\n",
    "                        initial=attrgetter('lon'))  # the previous longitude\n",
    "    prev_lat = Variable('prev_lat', dtype=np.float32, to_write=False,\n",
    "                        initial=attrgetter('lat'))  # the previous latitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-multiple",
   "metadata": {},
   "source": [
    "Now define a new function `TotalDistance` that calculates the sum of Euclidean distances between the old and new locations in each `RK4` step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TotalDistance(particle, fieldset, time):\n",
    "    \n",
    "    # Calculate the distance in latitudinal direction (using 1.11e2 kilometer per degree latitude)\n",
    "    lat_dist = (particle.lat - particle.prev_lat) * 1.11e2\n",
    "    # Calculate the distance in longitudinal direction, using cosine(latitude) - spherical earth\n",
    "    lon_dist = (particle.lon - particle.prev_lon) * 1.11e2 * math.cos(particle.lat * math.pi / 180)\n",
    "    # Calculate the total Euclidean distance travelled by the particle\n",
    "    particle.distance += math.sqrt(math.pow(lon_dist, 2) + math.pow(lat_dist, 2))\n",
    "\n",
    "    particle.prev_lon = particle.lon  # Set the stored values for next iteration.\n",
    "    particle.prev_lat = particle.lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-teddy",
   "metadata": {},
   "source": [
    ":::{Note} \n",
    "Here it is assumed that the latitude and longitude are measured in degrees North and East, respectively. However, some datasets give them measured in (kilo)meters, in which case we must not include the factor 1.11e2.\n",
    ":::\n",
    "\n",
    "We will run the `TotalDistance` function on a `ParticleSet` containing the five particles within the eReefs fieldset similar to the one we did above. \n",
    "\n",
    "Note that `pclass=DistParticle` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'U': data_name,\n",
    "             'V': data_name,\n",
    "            }\n",
    "\n",
    "variables = {'U': 'u',\n",
    "             'V': 'v'}\n",
    "\n",
    "dimensions = {'lat': 'latitude',\n",
    "              'lon': 'longitude',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "pset = ParticleSet.from_line(fieldset=fieldset, \n",
    "                             pclass=DistParticle,\n",
    "                             size=5,               # releasing 5 particles\n",
    "                             start=(147, -18.5),   # releasing on a line: the start longitude and latitude\n",
    "                             finish=(148, -17.5),  # releasing on a line: the end longitude and latitude\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-perry",
   "metadata": {},
   "source": [
    "Again we define a new kernel to include the function written above and execute the `ParticleSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nc_dist = 'CurrentParticlesDist.nc'\n",
    "try:\n",
    "    os.remove(output_nc_dist)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "file_dist = pset.ParticleFile(name=output_nc_dist, \n",
    "                                outputdt=timedelta(hours=1))\n",
    "\n",
    "k_dist = pset.Kernel(TotalDistance)  # Casting the TotalDistance function to a kernel.\n",
    "\n",
    "pset.execute(AdvectionRK4 + k_dist,  # Add kernels using the + operator.\n",
    "             runtime=timedelta(days=30),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=file_dist,\n",
    "             recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})\n",
    "\n",
    "file_dist.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-hammer",
   "metadata": {},
   "source": [
    "We can now print the distance in km that each particle has travelled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([p.distance for p in pset]) # the distances in km travelled by the particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-velvet",
   "metadata": {},
   "source": [
    "### Plotting the result\n",
    "\n",
    "We can extract the netcdf file values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_dist = xr.open_dataset(output_nc_dist)\n",
    "parcels_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-table",
   "metadata": {},
   "source": [
    "And plot the resulting parcels output on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "size = (9, 10)\n",
    "\n",
    "# Color from cmocean\n",
    "color = cmocean.cm.speed\n",
    "\n",
    "# Defining the figure\n",
    "fig = plt.figure(figsize=size, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Axes with Cartopy projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# and extent\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], ccrs.PlateCarree())\n",
    "\n",
    "# Plotting using Matplotlib \n",
    "# We plot the PH at the surface at the final recorded time interval\n",
    "cf = ds_hydro_clip.mean_cur.isel(time=10).plot( \n",
    "    transform=ccrs.PlateCarree(), cmap=color,\n",
    "    vmin = 0.1, vmax = 1.0, alpha=0.2, \n",
    "    add_colorbar=False\n",
    ")\n",
    "\n",
    "# Color bar\n",
    "cbar = fig.colorbar(cf, ax=ax, fraction=0.027, pad=0.045, \n",
    "                    orientation=\"horizontal\")\n",
    "cbar.set_label(ds_hydro_clip.mean_cur.long_name+' '+ds_hydro_clip.mean_cur.units, rotation=0, \n",
    "               labelpad=5, fontsize=10)\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "# Title\n",
    "plt.title('Parcels evolution coloured by travelled distance',\n",
    "          fontsize=13\n",
    "         )\n",
    "\n",
    "# Plot lat/lon grid \n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=0.1, color='k', alpha=1, \n",
    "                  linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 8}\n",
    "gl.ylabel_style = {'size': 8} \n",
    "\n",
    "# Add map features with Cartopy \n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', \n",
    "                                            edgecolor='face', \n",
    "                                            facecolor='lightgray'))\n",
    "ax.coastlines(linewidth=1)\n",
    "\n",
    "distmin = parcels_dist.distance.min().item()\n",
    "distmax = parcels_dist.distance.max().item()\n",
    "\n",
    "for k in range(parcels_dist.lon.shape[0]):\n",
    "    sc = plt.scatter(parcels_dist.lon.isel(traj=k), parcels_dist.lat.isel(traj=k), s=40, \n",
    "               c=parcels_dist.distance.isel(traj=k), edgecolors='w', \n",
    "               cmap='jet', vmin=distmin, vmax=distmax, \n",
    "               linewidth=0.2, transform=ccrs.PlateCarree()).set_zorder(11)\n",
    "\n",
    "# Color bar\n",
    "cbar2 = plt.colorbar(sc, ax=ax, fraction=0.027, pad=0.045)\n",
    "cbar2.set_label('Travelled distance in km', rotation=90, \n",
    "               labelpad=5, fontsize=10)\n",
    "cbar2.ax.tick_params(labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-repeat",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "[Tutorial](https://nbviewer.jupyter.org/github/OceanParcels/parcels/blob/master/parcels/examples/tutorial_output.ipynb) on how to analyse Parcels output         \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-validity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
